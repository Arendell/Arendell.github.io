[{"content":" 写在前面： 本文用于指导对本地部署大模型感兴趣的朋友，方便大家在个人机上体验纯私域大模型，本指导选用全开源软件方案，仅作为抛砖引玉的简单指导性文档，不额外讲解原理介绍、微调模型、训练模型等。由于部署在个人电脑，因此不额外部署docker，直接部署至windows，如需部署至docker请参考其他官方文档。\n一、方案介绍 考虑个人机主要为集成显共享显存，整体处理性能较弱，且没有独立CUDA、NPU来加速大模型推理，因此整体采用1.5b的超微量模型来体验，后端采用Ollama挂载开源大模型，前端使用Open-webui驱动Ollama，方便prompt和对话记录管理。参数量越大（b数值）意味着大模型性能更好，所需硬件成本也是指数级上涨，如电脑硬件更佳，可自行斟酌体验7b、14b、甚至70b、671b的大模型（选取原则及方法见3.1）。\n二、安装ollama 2.1 介绍 Ollama是一个开源框架，专门用于在本地机器上便捷部署和运行大型语言模型（LLM）。 Ollama的主要特点和功能包括：\n简化部署：Ollama旨在简化在Docker容器中部署大型语言模型的过程，使得非专业用户也能方便地管理和运行这些复杂的模型。 轻量级与可扩展：作为轻量级框架，Ollama保持较小的资源占用，同时具备良好的可扩展性，允许用户根据需要调整配置以适应不同规模的项目和硬件条件。 API支持：提供了一个简洁的API（能使用open-webUI调度的原因），使得开发者能够轻松创建、运行和管理大型语言模型实例，降低了与模型交互的技术门槛。 预构建模型库：包含一系列预先训练好的大型语言模型（纯净的，不需要去别的环境瞎找的大模型），用户可以直接选用这些模型应用于自己的应用程序，无需从头训练或自行寻找模型源。 模型导入与定制：支持从特定平台（如GGUF）导入已有的大型语言模型，兼容PyTorch（有微调需求的话兼容PyTorch很方便）或Safetensors深度学习框架，允许用户将基于这些框架训练的模型集成到Ollama中。 跨平台支持：提供针对macOS、Windows、Linux以及Docker的安装指南，确保用户能在多种操作系统环境下顺利部署和使用Ollama。 通过这些特点，Ollama使得开发者和研究人员能够在本地环境中高效利用大型语言模型进行各种自然语言处理任务，而无需依赖云服务或复杂的基础设施设置。 2.2 安装步骤 访问Ollama官网进行软件下载，注意此网站服务器部署于国外，因此下载软件、挂载大模型的过程可能缓慢or超时，请自行查找工具解决。 点击中间黑色Download按钮，跳转页面中下载Windows版本 安装过程几乎是傻瓜式的，全程只需要点【Install】就好，等右下角显示ollama is running的图标，即代表安装完成。同时打开CMD，键入ollama -v，能正确输出版本即为安装成功。 三、挂载大模型 3.1 如何选择大模型\n继续访问ollama的官网，点击左上角Models即可进入ollama支持的大模型列表 根据所需要的语言及电脑性能，选择合适的大模型，选取原则： Nvidia独立显卡（带有Cuda），根据显存大小选择，基本上1b参数=1G显存，例如6G以下显存的家用Nvidia显卡，选择7b、8b左右的轻量级模型。 集成显卡，根据性能、内存频宽可选择1.5b、2b、3b的超轻量级模型，处理器性能较强且内存频率\u0026amp;容量够大的，可以选择7b、8b左右的轻量级模型。 Nvidia旗舰独立显卡、专业计算卡，根据显存大小，可选择32b、70b模型，1b参数≈1G显存。 阵列专业计算卡、超融合大模型一体机，可选择405b、671b的满血大模型。 在这里考虑到大家的个人机均为集成显卡的笔记本，笔者下方以1.5b的超轻量级模型为例。\n3.2挂载大模型 上文除了提到电脑性能，还额外提到了一个关键词【语言】，由于训练语料不同，不同的大模型支持的语言不尽相同，例如国产对中文支持度最好的大模型是阿里团队的qwen2.5，以及通过qwen2.5蒸馏出的DeepseekR1（以下简称DSR1）:qwen。而使用英文语料训练的llama系列，显然不适用于中文场景。\nDSR1是DSv3的逻辑链增强，因此只有671b的满血版才是真正的DSR1，其他参数量的模型均蒸馏自对应参数量的模型，例如DSR1:7b蒸馏自qwen2.5:7b、DSR1:8b蒸馏自llama3.1:8b，此项内容在ollama的DSR1详情页面处均有标注。可以理解为qwen2.5带了逻辑链的大模型，本身推理能力相较于qwen2.5没有质的飞跃，仅加入了逻辑链推理过程。\n为方便大家顺利的安装至个人机，并体验最新的大模型推理逻辑链技术，笔者选择DSR1:qwen:1.5b的超轻量级模型举例安装。\n在ollama的DSR1详情页面，切换模型参数量至1.5b，复制右侧输出栏中的命令： 在cmd中键入对应命令【ollama run deepseek-r1:1.5b】，如报错请参考步骤二重新安装ollama。 键入后耐心等待ollama拉取对应模型至本地，由于ollama的镜像服务器在国外，此过程如果过慢，请自行寻找工具或挂载新的镜像服务器解决。 耐心等待出现success字样，且出现send a message 字样后，即代表挂载完成。 此状态下由原生Ollama已经可以进行模型推理，我们尝试键入【你好】，得到下列回复，即代表模型推理正常运行。至此完全本地的大模型（DSR1:qwen:1.5b）已正常挂载运行。 键入Ctrl+d或/bye可退出ollama的推理模式，更多ollama的命令详情见第五部分。 四、部署Open-webui方便对话记录管理\u0026amp;大模型调度 4.1 介绍 Open WebUI是一个可扩展、功能丰富且用户友好的自托管Web用户界面，专为完全离线操作设计。它支持多种大型语言模型(LLM)运行程序，包括Ollama和OpenAI兼容的API。 Open WebUI的主要特性包括：‌\n直观的界面：聊天界面来自于ChatGPT（使用体验和ChatGPT一致），确保了用户友好的体验。 响应式设计：支持流式文字传输（和微信聊天一样），提升互动体验。 代码语法高亮：通过语法高亮功能享受增强的代码可读性（支持代码自动识别、嵌入代码块方便阅读复制）。 全面支持Markdown和LaTeX：通过丰富的Markdown和LaTeX功能提升LLM体验（提升阅读体验）。 本地RAG集成：通过检索增强生成模型(RAG)支持，方便搭建本地知识库。 网络浏览能力：集成网络搜索引擎，随时将大模型接入网络检索。 提示预设支持：使用聊天输入中的/命令即时访问预设提示，加速互动。 对话标记：支持分类和定位特定聊天，以便快速参考和简化数据收集。 多模型支持：无缝切换不同的聊天模型，根据需求进行多样化的互动。 4.2 安装步骤 访问Open-webui的官方github页面，或访问官方docs文档页面，查看安装教程。 插一句题外话：Open-webui的官方指导是基于docker的，官方本意是基于docker能提升团队项目效率，提升项目高可用度👇，但是本指导仅用于指导【如何在个人机上部署本地大模型】，因此绕过docker直接部署至Windwos是本指导所选用的方案，如需要部署至Docker请参考上方的官方文档。\n安装Python3.11（重要），官方文档中明确介绍了open-webui需要Python3.11来作为前置环境，因此我们需要搭建对应的Python环境： 访问Python3.11的官方网站下载对应版本的Python安装包。 安装点击上方Install Now，整个过程几乎无障碍，为了方便可以点一个添加环境路径，如不会安装Python可自行百度，出现Setup was successful就代表安装完成。 此时重新打开CMD，输入python -V（注意V大写），如能正确输出版本为3.11.0即代表Python环境安装完成。 安装Open-webui，有了Python的前置环境，安装Open-webui就简单多了，我们只需要参考官方文档的pip命令，在CMD中键入【pip install open-webui】即可完成安装。因原生pip的镜像站在国外，因此安装过程可能缓慢or超时，请自行查找工具解决。待pip程序运行完成自动退出，即代表安装完成。 4.3 运行Open-webui 安装好后，在cmd中键入【open-webui serve】即可启动Open-webui，当命令行出现Open-WebUI的logo即为启动完成。 浏览器访问127.0.0.1:8080(本机host的8080端口)，即可访问Open-webui的网页,点击【开始探索】后，根据提示逐一创建管理员账号。 登录后耐心等待Open-webui调度ollama挂载的大模型，直到出现chat页面，整个安装过程完成。 五、对话LLM\u0026amp;附录FAQ 1.5b的DSR1整体逻辑较差，且自动调度逻辑链的机制不明确，为了解决这种问题可以使用(深度思考)前缀来强制调用DSR1的逻辑链模式。 Open-webui默认开启多轮对话，在右侧【高级参数设置】中可以调整输入至大模型的上下文长度，由于众所周知的原因，大模型会随着输入量、对话轮次的增多逐渐变慢，因此不建议进行过长的多轮对话，转而使用左上角的【新对话】创建新的聊天框来沟通。 点击头像，【管理员设置】如图操作路径，可以开启联网搜索功能，选择开源的【duckduckgo】搜索引擎，点击右下角保存，即可在聊天窗体内嵌入【联网搜索】功能（由于众所周知的原因，联网搜索功能需要自行配置对应的工具才能正常使用）\nollama命令：基本上和docker命令一样，非常简单。例如可以用ollama ps 查看正在运行的大模型（无调用5分钟左右ollama会自动释放资源，非常人性），利用ollama list可以查看挂载的大模型，同理cp复制、rm删除等 写在最后：自有大模型（chatGPT）以来，我们一直追求大模型的纯私域化、本地化，但根据目前的发展情况来判断，满血大模型本地化部署的成本仍然极高，而在消费级终端产品上可部署的1.5b、3b、7b的轻量级模型，整体性能较差（比较傻），仅可作为研究和探索使用，不具有明确的生产力。希望各位同事通过本指导能顺利进行大模型的本地化部署，并通过实践深入的理解大模型（Transformer）原理，学会利用大模型做大模型擅长的事，不陷入AI焦虑中。\n","date":"2025-03-17T11:34:35+08:00","image":"https://arendelle-image-bed.oss-cn-hangzhou.aliyuncs.com/%E5%8D%9A%E5%AE%A2%E5%9B%BE%E5%BA%8A/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20250211135621.png\"","permalink":"https://Arendell.github.io/p/%E5%A6%82%E4%BD%95%E5%9C%A8%E4%B8%AA%E4%BA%BA%E6%9C%BA%E4%B8%8A%E9%83%A8%E7%BD%B2%E6%9C%AC%E5%9C%B0%E5%A4%A7%E6%A8%A1%E5%9E%8B/","title":"如何在个人机上部署本地大模型"},{"content":" 个人最喜欢第三张\n","date":"2025-03-03T13:23:56+08:00","image":"https://arendelle-image-bed.oss-cn-hangzhou.aliyuncs.com/%E5%8D%9A%E5%AE%A2%E5%9B%BE%E5%BA%8A/%E8%8A%B1.jpg","permalink":"https://Arendell.github.io/p/%E4%B8%8D%E8%AF%AF%E6%98%A5/","title":"不误春"},{"content":"给主页添加篇幅\u0026amp;字数统计 灵感来源于：第三夏尔大佬代码总字数统计\n大佬原始代码\n在layouts/partials/footer/footer.html里增加以下代码：\n1 2 3 4 5 6 7 8 9 \u0026lt;!-- Add total page and word count time --\u0026gt; \u0026lt;section class=\u0026#34;totalcount\u0026#34;\u0026gt; {{$scratch := newScratch}} {{ range (where .Site.Pages \u0026#34;Kind\u0026#34; \u0026#34;page\u0026#34; )}} {{$scratch.Add \u0026#34;total\u0026#34; .WordCount}} {{ end }} 共发表了{{ len (where .Site.RegularPages \u0026#34;Section\u0026#34; \u0026#34;post\u0026#34;) }}篇文章 -- 共计{{ div ($scratch.Get \u0026#34;total\u0026#34;) 1000.0 | lang.FormatNumber 2 }}K字 \u0026lt;/section\u0026gt; 在assets/scss/partials/footer.scss里修改风格：\n1 2 3 4 5 .totalcount { color: var(--card-text-color-secondary); font-weight: normal; margin-bottom: 5px; } 个人代码\n但是由于大佬是直接加在全局footer里的，个人不喜欢这种样式，更喜欢只在homepage显示，另外想把位置挪动到上方，并且作为卡片样式和整体风格搭配，效果如下： 在layouts\\index.html内新增代码： 注意放在\n1 2 3 4 5 {{ $pag := .Paginate ($filtered) }} 。。。 。。。 \u0026lt;section class=\u0026#34;article-list\u0026#34;\u0026gt; 之间 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 \u0026lt;!-- 插入统计模块 --\u0026gt; \u0026lt;section class=\u0026#34;totalcount\u0026#34;\u0026gt; {{$scratch := newScratch}} {{ range (where .Site.Pages \u0026#34;Kind\u0026#34; \u0026#34;page\u0026#34; )}} {{$scratch.Add \u0026#34;total\u0026#34; .WordCount}} {{ end }} \u0026lt;div class=\u0026#34;count-box\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;count-item\u0026#34;\u0026gt; \u0026lt;span class=\u0026#34;count-icon\u0026#34;\u0026gt;📝\u0026lt;/span\u0026gt; \u0026lt;div\u0026gt; \u0026lt;strong\u0026gt;{{ len (where .Site.RegularPages \u0026#34;Section\u0026#34; \u0026#34;post\u0026#34;) }}\u0026lt;/strong\u0026gt; \u0026lt;span\u0026gt;篇文章\u0026lt;/span\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;count-item\u0026#34;\u0026gt; \u0026lt;span class=\u0026#34;count-icon\u0026#34;\u0026gt;🖋️🖋️\u0026lt;/span\u0026gt; \u0026lt;div\u0026gt; \u0026lt;strong\u0026gt;{{ div ($scratch.Get \u0026#34;total\u0026#34;) 1000.0 | lang.FormatNumber 2 }}\u0026lt;/strong\u0026gt; \u0026lt;span\u0026gt;千字\u0026lt;/span\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/section\u0026gt; 修改assets\\scss\\custom.scss对应的样式，保证卡片效果和暗黑模式适配\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 /* 统计模块美化 */ /* Total count statistics style */ .totalcount { display: flex; flex-direction: column; gap: var(--section-separation); background-color: var(--card-background); box-shadow: var(--shadow-l1); border-radius: var(--card-border-radius); padding: var(--card-padding); transition: box-shadow 0.3s ease; \u0026amp;:hover { box-shadow: var(--shadow-l2); } .count-box { display: flex; flex-direction: column; gap: 12px; font-family: var(--article-font-family); color: var(--card-text-color-main); // 主统计数字 strong { font-size: 2.8rem; font-weight: 600; color: var(--accent-color); @include respond(md) { font-size: 3.2rem; } } // 描述文字 span { font-size: 1.6rem; color: var(--card-text-color-secondary); line-height: 1.5; @include respond(md) { font-size: 1.8rem; } } // 辅助信息 .meta { display: flex; gap: 20px; margin-top: 15px; font-size: 1.4rem; color: var(--card-text-color-tertiary); div { display: flex; align-items: center; gap: 8px; svg { width: 18px; height: 18px; stroke: currentColor; } } } } // 响应式调整 @include respond(xl) { padding: calc(var(--card-padding) * 1.2); .count-box { gap: 15px; } } // 紧凑模式变体 \u0026amp;--compact { padding: var(--small-card-padding); .count-box { flex-direction: row; align-items: baseline; gap: 20px; strong { font-size: 2.2rem; } span { font-size: 1.4rem; } } } } 主页头像旋转 某个论坛里偶然看到的，非常有趣的代码\n在assets\\scss\\partials\\sidebar.scss内新增下列代码：\n1 2 3 4 5 6 7 .site-logo:hover{ transform: rotate(666turn); transition-delay: 1s; transition-property: all; transition-duration: 59s; transition-timing-function: cubic-bezier(.34,0,.84,1); } 并在原始的site-logo中新加入一行:\n1 transform: rotate(0turn); ","date":"2025-02-26T11:52:12+08:00","image":"https://arendelle-image-bed.oss-cn-hangzhou.aliyuncs.com/%E5%8D%9A%E5%AE%A2%E5%9B%BE%E5%BA%8A/20250226115657797.png","permalink":"https://Arendell.github.io/p/hugo%E5%8D%9A%E5%AE%A2%E8%A3%85%E4%BF%AE%E8%AE%B0%E5%BD%95%E9%95%BF%E6%9C%9F%E6%9B%B4%E6%96%B0/","title":"Hugo博客装修记录(长期更新❤)"},{"content":"为什么要做评论区 方便大火基于某一篇文章做互动，也方便作者了解大家对于某篇文章的想法。自新媒体时代大家就习惯于使用【评论区】之类的东西。逻辑功能清晰明了。\n方案介绍 交互式评论区这种东西，纯靠前端做在一个没有登录系统的静态网页上，显然是不现实的，因此hugo提供了大量的comment服务接口，方便大家接入各类提供评论的服务商。那即然是【商】就要赚钱，那么有没有一种方便快捷还开源的解决方案呢？有的兄弟，有的！\nGiscus，利用 GitHub Discussions 实现的评论系统 多的不说少的不唠，我们看看官网怎么写的\n开源（免费😍） 基于Github（大家都有账号） 简单部署至静态网页 这下完了，三个都是妥妥的痛点解决呀！不得不用了😭😭😭\n部署过程 其实我建议大家仔细阅读Giscus的官网，几乎是傻瓜式部署了。\n新建一个GitHub仓库，并确保他是Public状态。 给这个仓库开启Discussions功能，勾上就行。 把giscus.app安装到这个仓库，只选择安装到刚刚配置Discussions的仓库就行。 回到Giscus官网，基于刚刚创建的仓库名字，在官网获取配置文件。 配置如图选择。 向下滑，找到这一大堆参数。把他保存好 打开hugo的配置文件，一般是hugo.yaml，找到全局开关置为Enable，并把provider置为我们要用的giscus。 接着下滑，找到giscus的配置处，把刚刚官网给的配置，按名称依次输入。 行了，享受你的Giscus评论区吧~ ","date":"2025-02-25T14:05:37+08:00","image":"https://arendelle-image-bed.oss-cn-hangzhou.aliyuncs.com/%E5%8D%9A%E5%AE%A2%E5%9B%BE%E5%BA%8A/20250225141824373.png","permalink":"https://Arendell.github.io/p/%E5%A6%82%E4%BD%95%E7%BB%99%E5%8D%9A%E5%AE%A2%E6%B7%BB%E5%8A%A0%E8%AF%84%E8%AE%BA%E5%8C%BA/","title":"如何给博客添加评论区"},{"content":" 本文及后续文章的所有图片均采用此方案保存\n为什么要做图床 由于众所周知的原因，国内访问GitHub的速度极慢，甚至有时直接访问无法访问（DNS污染？😢）,因此把图片直接放到Github上，无论是阅读、上传还是维护起来都非常麻烦。另外就是有大量的摄影作品照片，后续也想放到博客来，一张JPG就是8-10M，如果挂Github实在是慢的出奇。那么有没有一种方法，即可以方便的上传图片，又可以在国内非常高效的访问呢？有的兄弟，有的。\n方案介绍 云端图床 因为之前工作经历和SDN相关，因此我第一时间就想到了使用国内的云服务来实现图床操作，现在问题来了，国内做云的这么多，选择哪家？\n阿里云 百度云 腾讯云 运营商云 简单搜索可知：\n百度云从诞生开始，在各家云服务器内就没啥竞争力。唯一有竞争力的产品是百度网盘，那玩意儿就不提供https外链，想保存图片只允许自己看or客户端链接分享，pass。 腾讯云当初做毕设的时候用过，对WX小程序支持度极好，当时学生白嫖了180天的ECS，现在秋后算账找我要大钱，pass。 运营商云，曾经工作相关不多解释，pass。 现在选择只剩一个了，只有阿里云能选了，阿里云我用过两次，第一次是2020年白嫖了90天的ECS，还有2024年SD火的时候，白嫖过他家的SD函数用来炼二次元丹，总体体验还是很好的，唯一的问题就是他家的控制台老更新，阿里黑话术语特别多，每次打开都头晕。为了避免阿里和腾子一样秋后找我算大钱。我们登录阿里云看看OSS的价格，夺少？\n9块兄弟们，9块一年。这不是炸了都夸他炸的响吗！？ 虽然只有40G，但是用作图床绰绰有余了，后续也可以方便的升级容量（秋后算大钱）。\n管理软件 好的现在云端OSS的问题解决了，现在还需要个软件能帮我：\n连接云端图床 一键上传图片 快捷生成MD链接 历史图片维护 简单在GitHub上检索下，立刻发现了🌟Star🌟巨高的PicGO,他的readme是这么写的： 那还等什么，直接跟Star然后下载安装！！！\n部署过程 购买OSS对象存储 登录阿里云，在上方选择产品, 找到OSS对象存储。 打开配置价格单，我的选择是： 标准 - 本地冗余（ LRS ）存储包 中国内地通用 40GB 一年 这样和算下来一年的价格是9元，当然为了避免秋后给我算大钱，我选择关闭了自动续费，如有需要可自行开启。 购买完成后点击对象存储控制台，开启OSS服务，这里会再进一遍购买菜单，但是开通费用是0元，未见明显异常（秋后算大钱🌚） 进入OSS的控制台，选择创建 bucket 按如下参数选择配置，建议选择距离工作/生活最近的节点，还有外部访问的权限，目前无法在创建页面打开，需要创建后单独开启。 开启外部访问，此步骤需要进入刚刚创建好的bucket控制台，打开外部访问权限，再开放外部读权限（你也不希望外部能写吧🤪） 给PicGO创建一个用户（说白了就是类似APIkey的东西，让软件可以管理云端图片，注意这个用户的权限和第六步我们开放的权限不是一回事，第六步只是让所有人通过阿里云的链接可以从公网访问到这个图片，而key权限可以直接管理整个OSS），刚刚的权限控制台找到最后一个RAM访问控制，并点击进入控制台。选择用户，新建用户，填写这些内容，记得勾选key让PicGO能登录 申请好后出现用户列表，务必保存好这些信息（说是关闭了不会再有哦） 给这个用户授权OSS管理权限，这样才能让持有key的PicGO上传图片 总算把阿里云的部分弄完了，阿里云的控制台可读性太差，全是阿里黑话SDN术语🤑\n安装配置PicGo 下载PicGO，记得给人家点点Star🌟 配置PicGO上的阿里云OSS 都设置好后，没有问题的话，就可以使用了 使用说明 怎么用PicGO，我觉得这个软件已经足够傻瓜，实在不懂也可以看看Github上的readme,再看不懂可以看看我怎么用：\n用WX/飞书/QQ/Windows等等等乱七八糟截图软件截个图 点这里，确定上传 自动copy图床链接（MD语法），直接粘贴到你的MD博客里 测试了下速度真快多了，比Github快了有3倍\n","date":"2025-02-25T10:10:38+08:00","image":"https://arendelle-image-bed.oss-cn-hangzhou.aliyuncs.com/%E5%8D%9A%E5%AE%A2%E5%9B%BE%E5%BA%8A/20250225101925662.png","permalink":"https://Arendell.github.io/p/%E5%A6%82%E4%BD%95%E4%BD%8E%E6%88%90%E6%9C%AC%E8%AE%BE%E7%BD%AE%E9%98%BF%E9%87%8C%E4%BA%91oss%E5%9B%BE%E5%BA%8A/","title":"如何低成本设置阿里云OSS图床"},{"content":"第一篇博客 为什么有这个网页 偶然在B站刷到了Letere-莱特雷 大佬 的视频，因讲解非常细致且通俗易懂，遂决定跟着一起部署；另外由于之前的文章、作品等大多散落在知乎、小红书、视觉中国、朋友圈等平台，也确实需要一个地方来集中管理和保存。🥰🥰🥰\n使用了什么技术 最开始已经提到，本网页是基于Letere-莱特雷 大佬 的视频讲解制作的，因此方案仿照他采用Hugo+github_page的方案实现，并利用GitHub的Action自动部署Hugo生成的静态网页。\n这个网页会更新什么内容 技术笔记笔记📃 摄影作品📸 趣味分享🎨 个人喜欢一切花里胡哨的东西，所以可能会在美化网页上做很多事🤷‍♀️\n这个网页会维护多久?更新频率？ 理论上只要大飞Github_Page活着就会一直更新,更新频率得看我的兴趣，有时候兴趣上头了就会一天三四更，犯懒了就不更了。\n","date":"2025-02-24T20:04:28+08:00","image":"https://arendelle-image-bed.oss-cn-hangzhou.aliyuncs.com/%E5%8D%9A%E5%AE%A2%E5%9B%BE%E5%BA%8A/pD6L94gfhyQLeNpV-generated_image.jpg","permalink":"https://Arendell.github.io/p/%E5%A4%A7%E9%A3%9E%E7%9A%84%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2/","title":"大飞的第一篇博客"}]